apiVersion: v1
kind: ConfigMap
metadata:
  name: airflow-config
  namespace: pdp-dev
  labels:
    tier: airflow
    component: config
data:
  # These are system-specified config overrides.
  airflow.cfg: |-
    [celery]
    flower_url_prefix =
    worker_concurrency = 16
    broker_url = ${AIRFLOW__CELERY__BROKER_URL}
    # result_backend will be set via AIRFLOW__CELERY__RESULT_BACKEND environment variable

    [celery_kubernetes_executor]
    kubernetes_queue = kubernetes

    [database] # Changed from [core] for sql_alchemy_conn as per modern practice
    # sql_alchemy_conn = postgresql+psycopg2://airflow:airflow@postgres-service/airflow # Overridden by env var AIRFLOW__DATABASE__SQL_ALCHEMY_CONN

    [core]
    # auth_manager = airflow.auth.managers.simple_auth_manager.SimpleAuthManager
    colored_console_log = False
    dags_folder = /opt/airflow/dags
    execution_api_server_url = http://airflow-api-server:8080/execution/
    executor = CeleryExecutor
    load_examples = True
    remote_logging = False

    [elasticsearch]
    json_format = True
    log_id_template = {dag_id}_{task_id}_{execution_date}_{try_number}

    [elasticsearch_configs]
    max_retries = 3
    retry_timeout = True
    timeout = 30

    [fab]
    enable_proxy_fix = True

    [kerberos]
    ccache = /var/kerberos-ccache/cache
    keytab = /etc/airflow.keytab
    principal = airflow@FOO.COM
    reinit_frequency = 3600

    [kubernetes]
    airflow_configmap = airflow-config
    airflow_local_settings_configmap = airflow-config
    multi_namespace_mode = False
    namespace = pdp-dev
    pod_template_file = /opt/airflow/pod_templates/pod_template_file.yaml
    worker_container_repository = apache/airflow
    worker_container_tag = 3.0.2

    [kubernetes_executor]
    multi_namespace_mode = False
    namespace = pdp-dev
    pod_template_file = /opt/airflow/pod_templates/pod_template_file.yaml
    worker_container_repository = apache/airflow
    worker_container_tag = 3.0.2

    [logging]
    colored_console_log = False
    remote_logging = False

    [metrics]
    statsd_host = airflow-statsd
    statsd_on = False
    statsd_port = 9125
    statsd_prefix = airflow

    [scheduler]
    run_duration = 41460
    standalone_dag_processor = True
    statsd_host = airflow-statsd
    statsd_on = True
    statsd_port = 9125
    statsd_prefix = airflow

    [webserver]
    enable_proxy_fix = True
    rbac = True

  airflow_local_settings.py: |-
---

  pod_template_file.yaml: |-
    apiVersion: v1
    kind: Pod
    metadata:
      name: dummy-pod-template # Name can be anything here, it's a template
    spec:
      # restartPolicy: Never # Common for task pods
      containers:
      - name: base
        image: "" # This will be overridden by Airflow or specific task definitions
        imagePullPolicy: IfNotPresent
        # args: ["echo", "This is a dummy pod template for Airflow."]
        # resources:
        #   limits:
        #     memory: "1Gi"
        #     cpu: "1"
        #   requests:
        #     memory: "512Mi"
        #     cpu: "0.5"
