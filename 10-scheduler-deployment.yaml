apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow-scheduler
  namespace: pdp-dev
  labels:
    tier: airflow
    component: scheduler
    executor: "CeleryExecutor"
spec:
  replicas: 1
  selector:
    matchLabels:
      tier: airflow
      component: scheduler
  template:
    metadata:
      labels:
        tier: airflow
        component: scheduler
    spec:
      restartPolicy: Always
      terminationGracePeriodSeconds: 10
      serviceAccountName: "pdp-default"
      securityContext:
        runAsUser: 71357
        fsGroup: 71357
      initContainers:
        - name: dag-fetcher
          image: docker-local.artifactory.medimpact.com/com/medimpact/pdp/medgen-dags-python:0.0.6
          imagePullPolicy: Always
          command:
            - "rsync"
            - "-av"
            - "--no-times"
            - "--no-perms"
            - "/source_files/dags/"
            - "/dags/"
          volumeMounts:
            - name: dags-volume
              mountPath: "/dags"
        - name: airflow-db-upgrade
          image: docker-local.artifactory.medimpact.com/com/medimpact/pdp/medgen-airflow-python:0.0.2-build99
          imagePullPolicy: Always
          command:
            - "/bin/bash"
            - "-c"
            - "exec airflow db upgrade"
          env:
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: airflow-postgres-creds
                  key: postgres_password
            - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN
              value: postgresql+psycopg2://airflow_user:$(POSTGRES_PASSWORD)@devedb0-vip.medimpact.com:5432/pdp_airflow_db
      containers:
        - name: scheduler
          image: docker-local.artifactory.medimpact.com/com/medimpact/pdp/medgen-airflow-python:0.0.2-build99
          imagePullPolicy: Always
          args:
            - "bash"
            - "-c"
            - "exec airflow scheduler"
          resources:
            {}
          volumeMounts:
            - name: dags-volume
              mountPath: "/opt/airflow/dags"
            - name: config
              mountPath: /opt/airflow/pod_templates/pod_template_file.yaml
              subPath: pod_template_file.yaml
              readOnly: true
            - name: logs
              mountPath: "/opt/airflow/logs"
            - name: config
              mountPath: "/opt/airflow/airflow.cfg"
              subPath: airflow.cfg
              readOnly: true
            - name: config
              mountPath: "/opt/airflow/config/airflow_local_settings.py"
              subPath: airflow_local_settings.py
              readOnly: true
          env:
            - name: AIRFLOW__CORE__EXECUTOR
              value: CeleryExecutor
            - name: AIRFLOW__CORE__LOAD_EXAMPLES
              value: "False"
            - name: AIRFLOW__CORE__FERNET_KEY
              valueFrom:
                secretKeyRef:
                  name: airflow-fernet-key
                  key: fernet-key
            - name: AIRFLOW__WEBSERVER__SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: airflow-webserver-secret-key
                  key: webserver-secret-key
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: airflow-postgres-creds
                  key: postgres_password
            - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN
              value: postgresql+psycopg2://airflow_user:$(POSTGRES_PASSWORD)@devedb0-vip.medimpact.com:5432/pdp_airflow_db
            - name: REDIS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: airflow-redis-password
                  key: password
            - name: AIRFLOW__CELERY__RESULT_BACKEND
              value: "redis://:$(REDIS_PASSWORD)@airflow-redis:6379/1"
            - name: AIRFLOW__CELERY__BROKER_URL
              valueFrom:
                secretKeyRef:
                  name: airflow-broker-url
                  key: connection
          livenessProbe:
            initialDelaySeconds: 10
            timeoutSeconds: 20
            failureThreshold: 5
            periodSeconds: 60
            exec:
              command:
                - sh
                - -c
                - |
                  CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR exec /entrypoint \
                  airflow jobs check --local --job-type SchedulerJob
          startupProbe:
            initialDelaySeconds: 15
            timeoutSeconds: 20
            failureThreshold: 10
            periodSeconds: 60
            exec:
              command:
                - sh
                - -c
                - |
                  CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR exec /entrypoint \
                  airflow jobs check --local --job-type SchedulerJob
        - name: scheduler-log-groomer
          image: docker-local.artifactory.medimpact.com/com/medimpact/pdp/medgen-airflow-python:0.0.2-build99
          imagePullPolicy: Always
          resources:
            {}
          args:
            - "bash"
            - "-c"
            - |
              sleep 60
              exec \
              airflow jobs check --local --job-type SchedulerJob --hostname $(hostname)
          volumeMounts:
            - name: logs
              mountPath: "/opt/airflow/logs"
            - name: config
              mountPath: "/opt/airflow/airflow.cfg"
              subPath: airflow.cfg
              readOnly: true
            - name: config
              mountPath: "/opt/airflow/config/airflow_local_settings.py"
              subPath: airflow_local_settings.py
              readOnly: true
      volumes:
        - name: dags-volume
          emptyDir: {}
        - name: config
          configMap:
            name: airflow-config
        - name: logs
          emptyDir: {}